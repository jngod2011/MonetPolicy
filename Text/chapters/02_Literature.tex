% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % 			Literature 			% % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %	

\subsection{Monetary Policy}

The primary objectives of monetary policy as well as actions in order to achieve their goals have varied over time, development status and  political system of an economy. \textcite{Mishkin.2007} makes a strong case about how the past decades after the Great Depression and their experiences have contributed to the current monetary system in the developed world, in particular in the U.S.A. as laid out below. 
% start with this since it's the aim of the paper, background for method later

\subsubsection{The beginnings of inflation targeting}
After the events of the Great Depression, the prevalent approach among monetary authorities as Keynesian and later influenced by \textcite{Samuelson.1960}. In their interpretation of the Phillip's curve, a trade-off between unemployment and inflation has to be resolved in the long-run. Hence, monetary and fiscal policy had the objective to achieve full employment at the cost of a slight rise in inflation. Alas, inflation exceeded the ten percent mark and employment even decreased compared to its level in the 1950s. 

Milton Friedman and his stream of monetarists argued, however, that there was no long-run trade-off but rather a natural rate of unemployment would be the equilibrium, irrespective on inflation. For this reason, monetary policy should target inflation instead of output, the determinant for employment, by ensuring a steady growth in the money supply. This argument was later confirmed by Robert Lucas' rational expectations theory. With the oil price shock of 1973, awareness of the importance of a nominal anchor rose as the high costs that inflation accommodates became more apparent. The mechanism of such an anchor would facilitate low and stable inflation expectations that lead to stable price and wage setting behaviour of firms, decreasing level and volatility of inflation.

With the realisation that expansive monetary policy does not lead to higher output in the long run, inflation is costly and a nominal anchor is beneficial, many industrialised nations adapted monetary targeting in the mid-1970s. Keeping inflation under control using this strategy hinges upon one critical assumption; there has to be a strong relationship between the goal variable, i.e. inflation or nominal income, and the target aggregate. During the 1980s, it became apparent that this was not valid any more and should be abandoned. %could also have been not properly persued before
Observing how successful German and Swiss central banking had become through the adoption of very transparent policy moves using target ranges, \textcite{Mishkin.2007} writes, a numerical and clearly communicated long-run goal would support in creating less volatile inflation expectations and still left the central bank enough leeway to deal with short-run fluctuations. 

Nevertheless, the prevalent monetary targeting strategy faced difficulties due to its weak relationship between money supply and nominal income, making it impossible to reach the desired inflation outcome. Furthermore, monetary aggregates were no longer a useful signal about the attitude of monetary authorities. As a result, monetary targeting could not properly be used as a nominal anchor and support steering inflation expectations in the vast majority of cases. 

In order to make use of advantages of monetary targeting compared with the German and Swiss communication strategy as well as providing a strong nominal anchor, inflation became the new target during the 1990s in many developed economies. Research by \textcite{Kydland.1977,Calvo.1978,Barro.1983} showed that a strong nominal anchor such as inflation could even solve the time-inconsistency problem. The defined long-run commitment to price stability, expressed through a numerical value, holds central banks accountable and makes their performance easy to assess and thus less vulnerable to influence for politicians who are  incentivised to use central bank tools for short-run expansive policy. Output, and thus employment, are still apparent in the monetary authorities' objective function as \textcite{Svensson.1997} showed. It does, however, consider the former's long-run perspective rather than cyclical behaviour as in the 1960s and 1970s and is thus referred to as \textit{flexible inflation targeting} by \textcite{Mishkin.2007}.

% references here?
Naturally, it is debatable whether central banks should adapt their strategy subject to current developments. The real estate bubble in the U.S.A stirred question about how to react to asset prices, including exchange rates while the following period of interest rates at the zero-lower-bound challenged central banks worldwide as their traditional instruments such as target rates could no longer be applied. Thus, central banks such as the FED and the ECB starting purchasing government bonds in order to raise inflation while smaller economies such as Sweden and Switzerland introduced slightly negative interest rates and the Czech Central Bank pegged the Czech Crown to the Euro. Furthermore, as \textcite{Mishkin.2007} points out, the prevalent opinion diverges about what extend of central bank transparency is still beneficial to an economy. He argues, that the relative weights of inflation and output in the goal function should stay occult as the public would not be able to identify when a central bank reacts to economic events and when it changes weights. As shown by \textcite{Ellingsen.2001}, reactions on the bond market indicated, however, that markets make inferences from FED statements which rationale is underlying a target rate change. % blabla methodology to check this in the following

% interest rate movements usually well predicted, more diffcult when (find the statement in paper) and size (?)
% \textcite{Cecchetti.2006} \dots

\subsubsection{History of FED actions and target rates}

% subsection: wrap up of fed actions during time period (interest rate momevements plus bond purchases)
% FED target history, analyses about yield curve movements

\subsection{Computational Linguistics and Machine Learning}

A good overview over techniques and applications of sentiment analysis is found in \textcite{Feldman.2013} and \textcite{Liu.2012} \dots

% why is this becoming more important and why can it be used for our purposes -> the Hess stuff
% lots of things have been done wrt sentiment in terms of pos/neg - adjust for engod/exog
% explain corpus
% pre-processing: remove stopwords, stemming, fuzzy matching (not needed here), etc

% Susan Athey: large magnitude of data -> not necessary anymore to identify 100 %, since magnitude so large, able to identify if there in many pieces

\subsection{Opinion Mining}

\textcite{Turney.2002} introduces an unsupervised three-step learning algorithm to mark a review as positive or negative\footnote{Neutral sentiment is ignored in many cases as a clear distinction from the non-neutral sentiments is not possible.} where first, \dots

% unsupervised: two approaches, see \textcite{Feldman.2013} - \textcite{Yu.2003} does sth interesting building on \textcite{Turney.2002}

\textcite{Pang.2002}, on the other hand, applies and compares three supervised learning techniques to classify reviews, namely na\"{i}ve Bayes, Maximum Entropy and Support Vector Machines (SVM). Other common classification algorithms entail Logistic Regression and k-nearest neighbours (KNN) \parencite{Feldman.2013}.

% identification of relevant articlesd not done, either first page... or just one column.... arbitrary! might lose info
% sure, important stff appears on front mages and in the same collumn, latter had issue (sometimes not mentioned);
% converesely, usiung all a) not feasible quantity & b) classification might be misslead (1. monet. pol. words, 2. suprise etc. words)
% former biased by construction as uncertainty is less news than a confident prediction
% unigrams and bigrams, n-grams

Most techniques use supervised learning according to \textcite{Wiebe.1999} which classifies sentences into the classes subjective or objective before determining the sentiment as the former classes usually do not express a positive or negative opinion. The importance of this observations stems from the fact that due to the vast amount of accessible data, computations are highly involved and thus can be made significantly more efficient by filtering articles with respect to their propensity to contribute to sentiment identification (or whatever other goal one might have in mind). 

% Turney 2002, thumbs up or down uses log-likelyhood ratio test to determine sentiment
% also: strength of sentiment - in my case maybe certainty? see Wilson 2004
% explicit aspects analysed, impicit not yet

Multilevel latent categorization as described in \textcite{Guo.2009} uses Latent Dirichlet Allocation (LDA) 

% careful with valence shifters, presuppositional items and modal auciliary verbs -> combine to unigram
% sarcasm, on the other hand should play less of an important role since 'boring' facts are reported -> different in blogs
% Opinion spam as in Jindal and Liu 2007, 2008 not an issue either

% include sentiment ontology tree for exog/endog classification (cf p. 106)
\textcite{Wang.2010} assume the overall review is a linear combination of its aspect ratings. Although they model the problem as Bayesian regression, \dots % p.112

In order to extract the sentiment of a statement, an opinion lexicon has to be created which entails a list of words and expressions that are used to express people's subjective feelings and opinions. Apart from manually creating this list or access available dictionaries such as WordNet\textsuperscript{\textregistered} by \textcite{Fellbaum.1998,Esuli.2006}, it is possible to rely on syntactic patterns in large corpora as has been suggested in \textcite{Ding.2008,Hatzivassiloglou.1997,Kanayama.2006,Turney.2002,Yu.2003}. See \textcite{Feldman.2013}. An elegant algorithm to to find WordNet\textsuperscript{\textregistered} synonyms and antonyms is suggested in \textcite{Kamps.2004} %explanation in \textcite{Feldman.2013}, p.86; put lexicon together through manual work and crowdsourcing

Apart from the direct rating through so called regular opinions as laied out above, \textcite{Ding.2009,Ganapathibhotla.2008,Jindal.2006}, among others, analyse comparative opinions. Since the latter is of merely of subordinate use for the classification of monetary policy task, we refer the reader to \textcite{Liu.2012} for an overview of the topic. 

%
As pointed out in \textcite{Hu.2004}, two techniques are most widely spread when it comes to discovering terms in corpora. Symbolic approaches that are based on terms such as noun phrases and their syntactic description encompass the first, statistical approaches the second while the latter make use of the fact that words composing a term a in close proximity to each other and reoccur. 

% DATA: 
% pre-selection of articles done through, among others, \textcite{Elastic.2015}
% Elastic: https://www.elastic.co/guide/en/elasticsearch/guide/current/getting-started.html

% For future: check which words are typical for authors, see Jane Austin stuff in the textbook