% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % 			Discussion 			% % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %	

As discussed above, the main prediction of the model in \textcite{Ellingsen.2001} could not be verified in this thesis. Since previous studies have shown empirical evidence for yield curve tilts after exogenous target rate adjustments and shifts after endogenous target rate adjustments, I believe the reason for this mismatch is due to two main differences when it comes to this analysis. First, the difference in sample periods is most likely the major factor to bias the regression outcomes. Secondly, the classification task has been conducted in an automated way rather than human inspection.

When it comes to the sample period, section~\ref{sec:Lit} describes how the conduct of monetary policy differed throughout the 20th century. \textcite{Ellingsen.2003} even noted a few adjustment dates that were completely unnoticed by markets and had to refer to previous studies in order to identify such. In the 21st century, however, transparency of monetary authorities has already become state of the art practice in the Western world and seen as an indispensable element of successful implementation of policy. Even more, due to the financial crisis of 2007 and its aftermath, the Fed took particular care to clearly laying out the future steps it intended to take in order to calm markets and aid resuming trust into the financial system. Hence, most steps were well communicated and expected before, even though not with clear dates they would come into action, and the moment of surprise was consequently much lower than during the 80s and 90s. As \textcite{Ellingsen.2003} point out, unanticipated Fed actions have a more pronounced impact on financial markets and thus this strategy of increased forward guidance might be one of the key reasons for why exogenous events have not had the influence on the yield curve that was expected. Naturally, the ZLB as well as QE engagements together with comparatively few target rate adjustments might have supported this fact as well, even though it is hard to explain the wrong sign on the coefficient for exogenous events for long maturities. 

The classification task, on the other hand, has been delegated to be performed by computer algorithms rather than the personal intervention of a trained economist. Even though this procedure clearly benefits due to its increase in objectivity and replicability, breaking texts down to a few terms is a strong simplification, especially for the highly specified task at hand. Nevertheless, since many results were comparable to \textcite{Ellingsen.2003} and running the program on their sample showed promising results, I am confident that the classification is of subordinate cause for the mismatch in empirical findings. Especially the ML section is in line, however,  with \textcite{Pang.2002} who compares NB, ME and svm to classify reviews and find that these algorithms perform not as good for sentiment classification as on classical topic-based categorization. Finally, as pointed out in section~\ref{sec:Res}, for a classification task with a specification level this high, a much larger training set compared to the action set is needed in order to achieve meaningful results. 