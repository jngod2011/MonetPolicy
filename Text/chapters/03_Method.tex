% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % 			Methodology			% % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % %	

\textcite{Liu.2012} summarizes the most influential papers in the area of sentiment analysis or opinion mining, a procedure to determine whether a snippet of text, be it in the form of a commentary on a product, post on social media or article in a newspaper, communicates a positive, negative or neutral message about the topic at stake using natural language processing (NLP). Application possibilities of these tools are ample, ranging from businesses improving their products through online reviews to automated fraud and insider trading detection through monitoring analysts messaging behaviour and are thus of major importance for businesses, individuals and policy makers alike. 
Building on \textcite{Liu.2012}, 
%AND others
I derive a procedure to extract an opinion on published articles by major international newspapers and agencies in order to determine the prevalent public opinion on the nature of a target rate move by the FED.

\subsection{Terminology}

As texts are as typical example of unstructured data, it needs to be converted to structured data in order to perform meaningful analyses. Therefore, we follow \textcite{Liu.2010} in defining an opinion as the quintuple\footnote{Even though the literature on opinion mining takes subjectivity and emotion into account \parencite{Wiebe.2000,Wiebe.2004,Riloff.2006}, we refrain from doing so as the source of the data comes from professional and reviewed media sources exclusively and the aim of the analysis is not to determine how individuals feel about a certain product or situation but rather extract the summary of public opinion from a newspaper article statement.} 
\begin{equation}
	(e_j, a_{jk}, so_{ijkl}, h_i, t_l)
\end{equation}
where $e_j$ is the target entity which forms the opinion target together with $a_{jk}$, an aspect of the former; $so_{ijkl}$ refers to the sentiment value of the opinion source, $h_i$, on $a_{jk}$ of $e_j$ at time $t_l$.
% e.g. entity is FED action, aspect is interest rate decision
% omit opinion holders
Since the first step of the analysis, the identification of relevant articles, as described in section\dots determines the opinion target while time and source are given exogenously, we focus on the discovering the sentiment of each text snippet. 

%how to get stuff out of the database: Long, Zhang and Zhu (2010) & Ma and Wan (2010)

Part-of-Speech (POS) tags as presented in table~\vref{tab:POS_tags} are applied to the articles through a pre-trained model by \textcite{OpenNLP.2016} that assigns POS tags based on the probability of what the correct POS tag is for newspaper language and selects the one with highest probability.

% Sentence-Document model see \textcite{McDonald.2007} (Sentiment_Proceedings2007_p470) 2.1 ff for notation

\subsection{Article identification}

\dots 
% before 07: factiva by hand
% after 07: use before 07 articles and some after 07 articles determined through TA and let elastic chose similar articles around a date

\subsection{Sentiment determination}

In order to identify the sentiment of each text piece as endogenous or exogenous, a list of words and expressions has to be set up which can be done in three different ways as discussed in section~\ref{sec:Lit}. The most straight forward one, which has been chosen here for its comprehensible and deterministic nature, being manually setting it up in a one-time effort. 

% Describe pre-processing process top down
% sufficient for our purposes to look for simple quant occurence of expressions, classification w/o increments as in rating
% always has to be trained for specific purpose (c.f. every product needs new algorithm when rated)

% sentiment words chosen through söderström/ellingsen paper together with WordNet

% reverse the polarity of a sentiment word whenever it is preceded by a negation.

% use dimension correlation as in \textcite{Godbole.2007} for the descriptive stats

% document based sentiment (in contrast to sentence-specific sentiment or aspect-specifi sentiment) as described in \texcite{Silge.2017} accompanied by their publish \textit{R} package \textcite{tidytextpackage}
% tf-itf: https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html is used instead of stopword stripping but we don't do that since we pre-select articles s.t. content is similar
% widely used term-weighting scheme according to wikipedia: https://en.wikipedia.org/wiki/Tf%E2%80%93idf -> not useful here since docs are pre-selected!

% Dictionary-based methods like the ones we are discussing find the total sentiment of a piece of text by adding up the individual sentiment scores for each word in the text. (http://tidytextmining.com/sentiment.html)